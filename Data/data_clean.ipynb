{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ef84980",
   "metadata": {},
   "source": [
    "## 1. Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e102e328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Rank;Word;Frequency;Frequency per million;Zipf value\n",
      "0                        1;you;257875407;38.758.605;75.884  \n",
      "1                         2;i;241866372;363.524.513;75.605  \n",
      "2                         3;the;201388773;30.268.679;7.481  \n",
      "3                        4;to;154325666;231.951.065;73.654  \n",
      "4                        5;'s;130877284;196.708.209;72.938  \n",
      "...                                                    ...  \n",
      "1048570                      23473;sanctii;7;0.0011;0.0414  \n",
      "1048571               23473;sanctions-free;7;0.0011;0.0414  \n",
      "1048572                  23473;sanctissime;7;0.0011;0.0414  \n",
      "1048573                 23473;sanctuaryand;7;0.0011;0.0414  \n",
      "1048574                  23473;sand-bikers;7;0.0011;0.0414  \n",
      "\n",
      "[1048575 rows x 1 columns] <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "def read_csv_file(file_path):\n",
    "    if not os.path.isfile(file_path):\n",
    "        raise FileNotFoundError(f\"The file {file_path} does not exist.\")\n",
    "    \n",
    "    with open(file_path, mode='r', newline='', encoding='utf-8') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        data = [row for row in reader]\n",
    "    \n",
    "    return data\n",
    "\n",
    "filepath = os.getcwd() + '/english_word_freq.csv'\n",
    "\n",
    "data = read_csv_file(filepath)\n",
    "\n",
    "data = pd.read_csv(filepath) # changing to pandas for easier data manipulation\n",
    "\n",
    "print(data, type(data)) # Uncomment this line to see the data read from the CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3d17f1",
   "metadata": {},
   "source": [
    "## 2. clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b94edd18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jr/39g71kvn2kq61zwnc2_grbsm0000gn/T/ipykernel_65590/2179755890.py:1: DtypeWarning: Columns (3,4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('english_word_freq.csv', sep=';')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data:\n",
      "  Word\n",
      "0  you\n",
      "1  the\n",
      "2  and\n",
      "3  for\n",
      "4  was\n",
      "Data shape: (10781, 1)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('english_word_freq.csv', sep=';')\n",
    "\n",
    "# Drop missing values\n",
    "data_clean = data.dropna()\n",
    "\n",
    "# Drop duplicate rows\n",
    "data_clean = data_clean.drop_duplicates(keep=False)\n",
    "\n",
    "# Column names\n",
    "word_col = data_clean.columns[1]       # the column with words\n",
    "freq_col = data_clean.columns[2]       # frequency column\n",
    "cols_to_drop = [data_clean.columns[0],  # first column\n",
    "                data_clean.columns[2],  # third column (original frequency, will sort anyway)\n",
    "                data_clean.columns[3],  # fourth column\n",
    "                data_clean.columns[4]]  # fifth column\n",
    "\n",
    "# Keep only alphabetic 3-letter words\n",
    "data_clean = data_clean[data_clean[word_col].str.isalpha()]\n",
    "data_clean = data_clean[data_clean[word_col].str.len() == 3]\n",
    "\n",
    "# Sort by frequency (descending)\n",
    "data_clean = data_clean.sort_values(by=freq_col, ascending=False)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "data_clean = data_clean.drop(columns=cols_to_drop)\n",
    "\n",
    "# Reset index\n",
    "data_clean = data_clean.reset_index(drop=True)\n",
    "\n",
    "# Save cleaned data\n",
    "cleaned_filepath = os.path.join(os.getcwd(), 'english_word_freq_cleaned.csv')\n",
    "data_clean.to_csv(cleaned_filepath, index=False)\n",
    "\n",
    "print(f\"Cleaned data:\\n{data_clean.head()}\\nData shape: {data_clean.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db089a20",
   "metadata": {},
   "source": [
    "## 3. Generate lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "420ec4e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random words:\n",
      "    0    1    2    3    4    5    6    7    8    9    10   11   12   13   14  \\\n",
      "0  air  van  pal  ink  ray  aah  gon  dug  ivy  uhh  fix  way  saw  add  won   \n",
      "1  lot  son  shi  rob  dry  leg  sec  ice  her  had  vic  out  tie  ahh  men   \n",
      "2  ago  kit  end  gal  him  yup  eve  jim  yay  hut  doo  rid  hat  dig  kim   \n",
      "3  app  rob  lee  bee  low  sub  sec  tae  pam  egg  oil  zoo  jay  rig  buy   \n",
      "4  aww  lee  tub  tag  bud  sub  odd  its  oil  owl  rot  log  may  ben  out   \n",
      "\n",
      "    15   16   17   18   19  \n",
      "0  chi  tea  war  our  cap  \n",
      "1  dad  ray  far  yan  was  \n",
      "2  ear  sam  los  jet  ran  \n",
      "3  cup  gee  joe  lot  put  \n",
      "4  gay  gun  can  yan  raj  \n",
      "data shape: (20, 20)\n"
     ]
    }
   ],
   "source": [
    "# Keep the first 400 words\n",
    "data_clean = data_clean.iloc[:400]\n",
    "\n",
    "# Generate 20 rows Ã— 20 words\n",
    "num_rows = 20\n",
    "num_words_per_row = 20\n",
    "random_words = []\n",
    "\n",
    "# Convert DataFrame column to list\n",
    "words_list = data_clean[word_col].tolist()\n",
    "\n",
    "for _ in range(num_rows):\n",
    "    row = random.sample(words_list, num_words_per_row)\n",
    "    random_words.append(row)\n",
    "\n",
    "random_words_df = pd.DataFrame(random_words)\n",
    "random_words_filepath = os.path.join(os.getcwd(), \"random_words.csv\")\n",
    "random_words_df.to_csv(random_words_filepath, index=False)\n",
    "\n",
    "print(f\"random words:\\n{random_words_df.head()}\\ndata shape: {random_words_df.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
