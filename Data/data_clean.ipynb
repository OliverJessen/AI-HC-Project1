{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ef84980",
   "metadata": {},
   "source": [
    "## 1. Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e102e328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Rank;Word;Frequency;Frequency per million;Zipf value\n",
      "0                        1;you;257875407;38.758.605;75.884  \n",
      "1                         2;i;241866372;363.524.513;75.605  \n",
      "2                         3;the;201388773;30.268.679;7.481  \n",
      "3                        4;to;154325666;231.951.065;73.654  \n",
      "4                        5;'s;130877284;196.708.209;72.938  \n",
      "...                                                    ...  \n",
      "1048570                      23473;sanctii;7;0.0011;0.0414  \n",
      "1048571               23473;sanctions-free;7;0.0011;0.0414  \n",
      "1048572                  23473;sanctissime;7;0.0011;0.0414  \n",
      "1048573                 23473;sanctuaryand;7;0.0011;0.0414  \n",
      "1048574                  23473;sand-bikers;7;0.0011;0.0414  \n",
      "\n",
      "[1048575 rows x 1 columns] <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "def read_csv_file(file_path):\n",
    "    if not os.path.isfile(file_path):\n",
    "        raise FileNotFoundError(f\"The file {file_path} does not exist.\")\n",
    "    \n",
    "    with open(file_path, mode='r', newline='', encoding='utf-8') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        data = [row for row in reader]\n",
    "    \n",
    "    return data\n",
    "\n",
    "filepath = os.getcwd() + '/english_word_freq.csv'\n",
    "\n",
    "data = read_csv_file(filepath)\n",
    "\n",
    "data = pd.read_csv(filepath) # changing to pandas for easier data manipulation\n",
    "\n",
    "print(data, type(data)) # Uncomment this line to see the data read from the CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3d17f1",
   "metadata": {},
   "source": [
    "## 2. clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b94edd18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jr/39g71kvn2kq61zwnc2_grbsm0000gn/T/ipykernel_65590/2179755890.py:1: DtypeWarning: Columns (3,4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('english_word_freq.csv', sep=';')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data:\n",
      "  Word\n",
      "0  you\n",
      "1  the\n",
      "2  and\n",
      "3  for\n",
      "4  was\n",
      "Data shape: (10781, 1)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('english_word_freq.csv', sep=';')\n",
    "\n",
    "# Drop missing values\n",
    "data_clean = data.dropna()\n",
    "\n",
    "# Drop duplicate rows\n",
    "data_clean = data_clean.drop_duplicates(keep=False)\n",
    "\n",
    "# Column names\n",
    "word_col = data_clean.columns[1]       # the column with words\n",
    "freq_col = data_clean.columns[2]       # frequency column\n",
    "cols_to_drop = [data_clean.columns[0],  # first column\n",
    "                data_clean.columns[2],  # third column (original frequency, will sort anyway)\n",
    "                data_clean.columns[3],  # fourth column\n",
    "                data_clean.columns[4]]  # fifth column\n",
    "\n",
    "# Keep only alphabetic 3-letter words\n",
    "data_clean = data_clean[data_clean[word_col].str.isalpha()]\n",
    "data_clean = data_clean[data_clean[word_col].str.len() == 3]\n",
    "\n",
    "# Sort by frequency (descending)\n",
    "data_clean = data_clean.sort_values(by=freq_col, ascending=False)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "data_clean = data_clean.drop(columns=cols_to_drop)\n",
    "\n",
    "# Reset index\n",
    "data_clean = data_clean.reset_index(drop=True)\n",
    "\n",
    "# Save cleaned data\n",
    "cleaned_filepath = os.path.join(os.getcwd(), 'english_word_freq_cleaned.csv')\n",
    "data_clean.to_csv(cleaned_filepath, index=False)\n",
    "\n",
    "print(f\"Cleaned data:\\n{data_clean.head()}\\nData shape: {data_clean.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db089a20",
   "metadata": {},
   "source": [
    "## 3. Generate lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "420ec4e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random words:\n",
      "    0    1    2    3    4    5    6    7    8    9    10   11   12   13   14  \\\n",
      "0  jon  gun  war  ace  aha  lou  jae  lot  hid  sit  bat  pop  bit  did  fed   \n",
      "1  pay  gps  are  nut  lay  sub  owl  hey  lap  joe  out  tap  dan  wha  now   \n",
      "2  ran  con  pig  fog  won  how  led  cos  gas  liu  gee  ray  bed  own  bey   \n",
      "3  cat  gon  kid  ann  nap  fat  ron  nor  cal  del  fun  ceo  lad  dna  roy   \n",
      "4  zoe  fan  seo  aye  one  via  kit  dip  max  sad  mac  box  ivy  pan  erm   \n",
      "\n",
      "    15   16   17   18   19  \n",
      "0  yet  net  saw  gay  wes  \n",
      "1  aww  bad  any  fly  hat  \n",
      "2  gus  rot  gin  job  who  \n",
      "3  rob  gig  gal  map  rig  \n",
      "4  hit  toy  pal  sec  doc  \n",
      "data shape: (20, 20)\n"
     ]
    }
   ],
   "source": [
    "# Keep the first 400 words\n",
    "data_clean = data_clean.iloc[:400]\n",
    "\n",
    "num_rows = 20\n",
    "num_words_per_row = 20\n",
    "\n",
    "# Convert DataFrame column to list\n",
    "words_list = data_clean[word_col].tolist()\n",
    "\n",
    "# Shuffle the full list of 400 words\n",
    "random.shuffle(words_list)\n",
    "\n",
    "# Partition into 20 lists of 20 words each\n",
    "random_words = [words_list[i * num_words_per_row : (i + 1) * num_words_per_row] \n",
    "                for i in range(num_rows)]\n",
    "\n",
    "# Convert to DataFrame\n",
    "random_words_df = pd.DataFrame(random_words)\n",
    "\n",
    "# Save to CSV\n",
    "random_words_filepath = os.path.join(os.getcwd(), \"random_words.csv\")\n",
    "random_words_df.to_csv(random_words_filepath, index=False)\n",
    "\n",
    "print(f\"random words:\\n{random_words_df.head()}\\ndata shape: {random_words_df.shape}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
