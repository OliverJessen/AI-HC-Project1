{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ef84980",
   "metadata": {},
   "source": [
    "## 1. Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e102e328",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jr/39g71kvn2kq61zwnc2_grbsm0000gn/T/ipykernel_43666/781995006.py:21: DtypeWarning: Columns (3,4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('english_word_freq.csv', sep=';')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Rank;Word;Frequency;Frequency per million;Zipf value\n",
      "0                        1;you;257875407;38.758.605;75.884  \n",
      "1                         2;i;241866372;363.524.513;75.605  \n",
      "2                         3;the;201388773;30.268.679;7.481  \n",
      "3                        4;to;154325666;231.951.065;73.654  \n",
      "4                        5;'s;130877284;196.708.209;72.938  \n",
      "...                                                    ...  \n",
      "1048570                      23473;sanctii;7;0.0011;0.0414  \n",
      "1048571               23473;sanctions-free;7;0.0011;0.0414  \n",
      "1048572                  23473;sanctissime;7;0.0011;0.0414  \n",
      "1048573                 23473;sanctuaryand;7;0.0011;0.0414  \n",
      "1048574                  23473;sand-bikers;7;0.0011;0.0414  \n",
      "\n",
      "[1048575 rows x 1 columns] <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "def read_csv_file(file_path):\n",
    "    if not os.path.isfile(file_path):\n",
    "        raise FileNotFoundError(f\"The file {file_path} does not exist.\")\n",
    "    \n",
    "    with open(file_path, mode='r', newline='', encoding='utf-8') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        data = [row for row in reader]\n",
    "    \n",
    "    return data\n",
    "\n",
    "filepath = os.getcwd() + '/english_word_freq.csv'\n",
    "\n",
    "data = read_csv_file(filepath)\n",
    "\n",
    "data = pd.read_csv(filepath) # changing to pandas for easier data manipulation\n",
    "\n",
    "print(data, type(data)) # Uncomment this line to see the data read from the CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3d17f1",
   "metadata": {},
   "source": [
    "## 2. clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b94edd18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jr/39g71kvn2kq61zwnc2_grbsm0000gn/T/ipykernel_43666/2179755890.py:1: DtypeWarning: Columns (3,4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('english_word_freq.csv', sep=';')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data:\n",
      "  Word\n",
      "0  you\n",
      "1  the\n",
      "2  and\n",
      "3  for\n",
      "4  was\n",
      "Data shape: (10781, 1)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('english_word_freq.csv', sep=';')\n",
    "\n",
    "# Drop missing values\n",
    "data_clean = data.dropna()\n",
    "\n",
    "# Drop duplicate rows\n",
    "data_clean = data_clean.drop_duplicates(keep=False)\n",
    "\n",
    "# Column names\n",
    "word_col = data_clean.columns[1]       # the column with words\n",
    "freq_col = data_clean.columns[2]       # frequency column\n",
    "cols_to_drop = [data_clean.columns[0],  # first column\n",
    "                data_clean.columns[2],  # third column (original frequency, will sort anyway)\n",
    "                data_clean.columns[3],  # fourth column\n",
    "                data_clean.columns[4]]  # fifth column\n",
    "\n",
    "# Keep only alphabetic 3-letter words\n",
    "data_clean = data_clean[data_clean[word_col].str.isalpha()]\n",
    "data_clean = data_clean[data_clean[word_col].str.len() == 3]\n",
    "\n",
    "# Sort by frequency (descending)\n",
    "data_clean = data_clean.sort_values(by=freq_col, ascending=False)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "data_clean = data_clean.drop(columns=cols_to_drop)\n",
    "\n",
    "# Reset index\n",
    "data_clean = data_clean.reset_index(drop=True)\n",
    "\n",
    "# Save cleaned data\n",
    "cleaned_filepath = os.path.join(os.getcwd(), 'english_word_freq_cleaned.csv')\n",
    "data_clean.to_csv(cleaned_filepath, index=False)\n",
    "\n",
    "print(f\"Cleaned data:\\n{data_clean.head()}\\nData shape: {data_clean.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db089a20",
   "metadata": {},
   "source": [
    "## 3. Generate lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "420ec4e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random words:\n",
      "    0    1    2    3    4    5    6    7    8    9    10   11   12   13   14  \\\n",
      "0  kav  jug  ebr  nwk  uab  cpb  lvr  lwt  kwh  anv  cmz  qmu  tun  fpt  bet   \n",
      "1  dst  vmm  rkf  npw  muh  ebg  qct  zit  psh  gtp  big  ild  cfv  ftf  ckx   \n",
      "2  dvw  kap  vbb  bcz  igr  bmm  dou  baq  arm  fic  oog  bhm  lni  hsy  fyc   \n",
      "3  awf  ewn  fwb  tmf  fjd  qao  bna  gad  spv  dga  cbi  rig  rld  vov  pao   \n",
      "4  vnr  wau  sjt  gki  wsa  unf  uer  llt  snf  bmr  cka  jnz  vru  vug  oow   \n",
      "\n",
      "    15   16   17   18   19  \n",
      "0  dvv  uny  dov  ncw  hlv  \n",
      "1  yon  kul  rfn  hsu  ggs  \n",
      "2  opi  tze  sul  wgu  mnl  \n",
      "3  rdc  fpo  unn  dhq  tsn  \n",
      "4  uge  jbu  amo  qed  nxl  \n",
      "data shape: (20, 20)\n"
     ]
    }
   ],
   "source": [
    "# Generate 20 rows Ã— 20 words\n",
    "num_rows = 20\n",
    "num_words_per_row = 20\n",
    "random_words = []\n",
    "\n",
    "words_list = data_clean[first_col].tolist()\n",
    "\n",
    "for _ in range(num_rows):\n",
    "    row = random.sample(words_list, num_words_per_row)\n",
    "    random_words.append(row)\n",
    "\n",
    "random_words_df = pd.DataFrame(random_words)\n",
    "random_words_filepath = os.path.join(os.getcwd(), \"random_words.csv\")\n",
    "random_words_df.to_csv(random_words_filepath, index=False)\n",
    "\n",
    "print(f\"random words:\\n{random_words_df.head()}\\ndata shape: {random_words_df.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
