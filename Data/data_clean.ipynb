{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ef84980",
   "metadata": {},
   "source": [
    "## 1. Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e102e328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           word        count\n",
      "0           the  23135851162\n",
      "1            of  13151942776\n",
      "2           and  12997637966\n",
      "3            to  12136980858\n",
      "4             a   9081174698\n",
      "...         ...          ...\n",
      "333328    gooek        12711\n",
      "333329   gooddg        12711\n",
      "333330  gooblle        12711\n",
      "333331   gollgo        12711\n",
      "333332    golgw        12711\n",
      "\n",
      "[333333 rows x 2 columns] <class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def read_csv_file(file_path):\n",
    "    if not os.path.isfile(file_path):\n",
    "        raise FileNotFoundError(f\"The file {file_path} does not exist.\")\n",
    "    \n",
    "    with open(file_path, mode='r', newline='', encoding='utf-8') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        data = [row for row in reader]\n",
    "    \n",
    "    return data\n",
    "\n",
    "filepath = os.getcwd() + '/unigram_freq.csv'\n",
    "\n",
    "data = read_csv_file(filepath)\n",
    "\n",
    "data = pd.read_csv(filepath) # changing to pandas for easier data manipulation\n",
    "\n",
    "print(data, type(data)) # Uncomment this line to see the data read from the CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3d17f1",
   "metadata": {},
   "source": [
    "## 2. clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b94edd18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned data:\n",
      "  word\n",
      "0  the\n",
      "1  and\n",
      "2  for\n",
      "3  you\n",
      "4  not\n",
      "data shape: (12976, 1)\n"
     ]
    }
   ],
   "source": [
    "# Drop missing values\n",
    "data_clean = data.dropna()\n",
    "\n",
    "# Drop duplicate rows\n",
    "data_clean = data_clean.drop_duplicates(keep=False)\n",
    "\n",
    "# Keep only rows where first column (assume it's the first by index, not by name) has length == 3\n",
    "first_col = data_clean.columns[0]\n",
    "data_clean = data_clean[data_clean[first_col].str.len() == 3]\n",
    "\n",
    "# sort by second column (the second column is frequency count, so we want to keep the most common words)\n",
    "second_col = data_clean.columns[1]\n",
    "data_clean = data_clean.sort_values(by=second_col, ascending=False)\n",
    "\n",
    "# drop second column (assume it's the second by index, not by name)\n",
    "second_col = data_clean.columns[1]\n",
    "data_clean = data_clean.drop(columns=[second_col])\n",
    "\n",
    "# Reset index\n",
    "data_clean = data_clean.reset_index(drop=True)\n",
    "\n",
    "print(f\"cleaned data:\\n{data_clean.head()}\\ndata shape: {data_clean.shape}\") # Uncomment this line to see the cleaned data\n",
    "\n",
    "# Save cleaned data to a new CSV file\n",
    "cleaned_filepath = os.getcwd() + '/unigram_freq_cleaned.csv'\n",
    "data_clean.to_csv(cleaned_filepath, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db089a20",
   "metadata": {},
   "source": [
    "## 3. Generate lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420ec4e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random words:\n",
      "    0    1    2    3    4    5    6    7    8    9    10   11   12   13   14  \\\n",
      "0  bno  ivw  yrt  ijl  zas  eaz  gpb  ffy  ste  ael  awt  rnc  cbs  abs  sjn   \n",
      "1  rgj  ecf  ooh  kvo  bms  pbw  qgd  jnt  tni  gbl  cha  kha  prg  ugc  zoe   \n",
      "2  rtk  dek  dob  uwb  dol  mkw  zad  ark  qrw  ide  jsw  afr  ibn  lhe  vlx   \n",
      "3  hgx  its  aqj  ehh  oic  epe  vwr  unq  lvq  vcv  zpi  cts  kbe  mub  imw   \n",
      "4  pcm  bav  nul  ios  nia  wpe  hur  gbr  ndc  ezu  hxw  hte  wid  trz  hlf   \n",
      "\n",
      "    15   16   17   18   19  \n",
      "0  lqd  ddx  hav  oem  bfy  \n",
      "1  nts  oyl  bid  umg  yzz  \n",
      "2  fxb  woz  uge  whj  roq  \n",
      "3  ofo  obl  khr  mvl  vwb  \n",
      "4  map  nku  bxd  ovd  apu  \n",
      "data shape: (20, 20)\n"
     ]
    }
   ],
   "source": [
    "# generate 20 rows with 20 random words from the cleaned data\n",
    "import random\n",
    "num_rows = 20\n",
    "num_words_per_row = 20\n",
    "random_words = []\n",
    "\n",
    "# Get list of words from the first column\n",
    "words_list = data_clean[first_col].tolist()\n",
    "\n",
    "# fetch random words\n",
    "for _ in range(num_rows):\n",
    "    row = random.sample(words_list, 3)\n",
    "    random_words.append(row)\n",
    "\n",
    "random_words_df = pd.DataFrame(random_words)\n",
    "random_words_filepath = os.getcwd() + '/random_words.csv'\n",
    "random_words_df.to_csv(random_words_filepath, index=False)\n",
    "\n",
    "print(f\"random words:\\n{random_words_df.head()}\\ndata shape: {random_words_df.shape}\") # Uncomment this line to see the random words data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
